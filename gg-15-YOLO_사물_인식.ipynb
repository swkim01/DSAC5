{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "gg-15-YOLO 사물 인식.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_GYGttzoy9ij"
      },
      "source": [
        "<h1>YOLO 사물 인식</h1>\r\n",
        "\r\n",
        "<table class=\"tfo-notebook-buttons\" align=\"left\">\r\n",
        "  <td>\r\n",
        "    <a target=\"_blank\" href=\"https://colab.research.google.com/github/swkim01/DSAC5/blob/main/gg-15-YOLO_사물_인식.ipynb\"><img src=\"https://github.com/swkim01/DSAC5/raw/main/colab_logo_32px.png\" />구글 코랩에서 실행</a>\r\n",
        "  </td>\r\n",
        "  <td>\r\n",
        "    <a target=\"_blank\" href=\"https://github.com/swkim01/DSAC5/blob/main/gg-15-YOLO_사물_인식.ipynb\"><img src=\"https://github.com/swkim01/DSAC5/raw/main/GitHub-Mark-32px.png\" />깃헙에서 소스 보기</a>\r\n",
        "  </td>\r\n",
        "</table>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZXV8cTaNy9ik"
      },
      "source": [
        "<h3>이 장에서는 YOLO를 사용하는 방법만을 실습해보도록 한다.</h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8CkIaa6B-6JX"
      },
      "source": [
        "실습예제의 YOLO_v3_tutorial_from_scratch-master.zip 파일을 코랩 환경의 '/content/sample_data'로 업로드한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBN99qujGJwX"
      },
      "source": [
        "#%%shell\n",
        "\n",
        "#unzip ../YOLO_v3_tutorial_from_scratch-master.zip -d yolo\n",
        "from zipfile import ZipFile\n",
        "with ZipFile('data/YOLO_v3_tutorial_from_scratch-master.zip', 'r') as zf:\n",
        "    zf.extractall('yolo/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247
        },
        "id": "GglpubQPy9ik",
        "outputId": "40318d25-d42e-4821-cee8-b1c20da9a3cf"
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "#from google.colab.patches import cv2_imshow\n",
        "\n",
        "# Load Yolo\n",
        "net = cv2.dnn.readNet(\"yolo/yolov3.weights\", \"yolo/cfg/yolov3.cfg\")\n",
        "classes = []\n",
        "with open(\"yolo/data/coco.names\", \"r\") as f:\n",
        "    classes = [line.strip() for line in f.readlines()]\n",
        "layer_names = net.getLayerNames()\n",
        "output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
        "colors = np.random.uniform(0, 255, size=(len(classes), 3))\n",
        "\n",
        "# Loading image\n",
        "img = cv2.imread(\"yolo/imgs/dog.jpg\")\n",
        "img = cv2.resize(img, None, fx=0.4, fy=0.4)\n",
        "height, width, channels = img.shape\n",
        "\n",
        "# Detecting objects\n",
        "blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
        "net.setInput(blob)\n",
        "outs = net.forward(output_layers)\n",
        "\n",
        "# Showing informations on the screen\n",
        "class_ids = []\n",
        "confidences = []\n",
        "boxes = []\n",
        "for out in outs:\n",
        "    for detection in out:\n",
        "        scores = detection[5:]\n",
        "        class_id = np.argmax(scores)\n",
        "        confidence = scores[class_id]\n",
        "        if confidence > 0.5:\n",
        "            # Object detected\n",
        "            center_x = int(detection[0] * width)\n",
        "            center_y = int(detection[1] * height)\n",
        "            w = int(detection[2] * width)\n",
        "            h = int(detection[3] * height)\n",
        "            # Rectangle coordinates\n",
        "            x = int(center_x - w / 2)\n",
        "            y = int(center_y - h / 2)\n",
        "            boxes.append([x, y, w, h])\n",
        "            confidences.append(float(confidence))\n",
        "            class_ids.append(class_id)\n",
        "indexes = cv2.dnn.NMSBoxes(boxes, confidences, 0.5, 0.4)\n",
        "font = cv2.FONT_HERSHEY_PLAIN\n",
        "for i in range(len(boxes)):\n",
        "    if i in indexes:\n",
        "        x, y, w, h = boxes[i]\n",
        "        label = str(classes[class_ids[i]])\n",
        "        color = colors[i]\n",
        "        cv2.rectangle(img, (x, y), (x + w, y + h), color, 2)\n",
        "        cv2.putText(img, label, (x, y + 30), font, 3, color, 3)\n",
        "\n",
        "#cv2_imshow(\"img)\n",
        "cv2.imshow(\"result\", img)\n",
        "cv2.waitKey(0)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "-1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yvcrp57y7xo5"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}